---
title: Linux的内存寻址
categories:
  - 操作系统
  - Linux
tags:
  - 页表
  - 段
excerpt: 本文综合了我对本科操作系统课程的回顾已经对Linux下内存寻址的理解
---
<!-- more -->

写在前面，本文所讨论的是基于`x86_64`架构上的`Linux`。

#### 内存地址

​	众所周知，在计算机实际运行的时候，物理地址(PA)是唯一。CPU等资源的数量是固定的，而进程却可以有很多，这就导致了直接访问物理地址这一方式，不仅很复杂，而且安全性差，且难以对内存进行管理。因此引入了逻辑地址即虚拟地址(VA),所有的进程访问的地址都是`VA`，在通过`MMU`（内存管理单元，负责地址转化的实际物理电路）进行从`VA`到`PA`的映射。



#### 逻辑地址的组成

​	由于技术的发展，在比较早的时期，Linux是通过逻辑地址到线性地址再到物理地址的转化。其中结合了段寻址和页寻址，而现在段寻址的方式已经被基本遗弃，更多的是直接使用页寻址的方式，通过四级页表的方式从逻辑地址到物理地址的转化。并且保存了对`LDT(local description table)`和`GDT(global description table)`的支持，当对应的字段有效时，才使用段寻址的方式去查询。因此本文着重介绍使用页寻址的方式。

​	进程的所使用的地址空间就是用虚拟地址来表示的，同样的进程的地址空间被划分为了用户态虚拟地址和内核态虚拟地址。这部分的内容会在Linux的进程中有更详细的介绍。

#### 硬件中的分页

​	现代分页的最小页表是`4KB`的大小，当然也会有一些大页（`2MB`），超大页（`1GB`）的出现，不过这些大页也都是大页和超大页是通过页表的上层（`PD、PDPT`）**直接映射大块连续物理内存**来实现的，并且管理方式有些不同。

​	同时，必须强调的一点是，现代CPU是无法直接访问内存的，而是通过利用局部性原理，使用多级缓存的设计来保证高速访问，因此根据最终转换的PA，去高速缓存中读取数据（即使发生缓存不命中，也会从内存中读入数据到高速缓存中）。为了叙述简便，后续我们仍使用“访问内存”这一表达，代表的是**通过物理地址最终完成的数据访问过程**，不论数据是否实际命中 cache。

#### Linux中的分页

​	现在的Linux采用的是4级分页模型，分别是页全局目录，页上级目录，页中间目录，页表。缩写分别为：`PGD`，`PUD`，`PMD`，`PT`。通过这四级别的映射之后，得到最终的`PTE`，最后用`PTE`的帧地址加上虚拟地址的偏移得到最终的`PA`。每次从VA到PA的转化，首先要依据`CR3`寄存器中的页全局地址，和VA前面的字段，按照上述规则去计算得到最终的PA。

#### TLB（Translation Lookaside Buffer）

​	`TLB`，即快表，是一块保存在`MMU`中的高速缓存区，用来直接保存VA到PA的映射，从而不用去多级查找，以此来提高效率。（这里也是利用了局部性原理），不过要注意区分的是，`TLB`不是保存在`Cache`中的，它是保存在`MMU`中独立的高速缓存区。因此实际的内存访问，是首先在`TLB`中访问，如果没有找到对应项，再去使用多级页表查询的方式去访问，同时更新`TLB`。

#### 最终的内存访问方式

当然可以，以下是你文档中“最终的内存访问方式”这一节的补充内容，风格与上文保持一致：

------

#### 最终的内存访问方式

​	结合上述机制，可以梳理出 Linux 在 `x86_64` 架构下完整的一次内存访问过程。假设当前 CPU 执行一个访问内存的指令（如读取变量、访问数组等），它首先会提供一个 **虚拟地址 VA**。这段地址会依次经历以下步骤，最终转换为物理地址并完成访问：

1. **TLB 查询**：CPU 首先将 VA 提交给 MMU，MMU 会在 `TLB` 中查找是否存在该虚拟页的映射（即页帧地址）。如果查找命中（称为 **TLB hit**），则立即得到物理页帧号，再与 VA 的页内偏移合并，得到最终的物理地址。
2. **页表查找（TLB miss）**：若 TLB 中未命中（**TLB miss**），则 MMU 会从 `CR3` 寄存器中获取当前活动页表的基地址，按虚拟地址的高位字段，逐级遍历页表结构（PGD → PUD → PMD → PT），最终得到 `PTE` 中的物理页帧地址。
3. **更新 TLB**：一旦找到有效的页表项，MMU 会将该 VA → PA 的映射（准确说是PA所在的页表的帧地址）插入到 `TLB` 中，以便未来的访问能更快命中。
4. **访问 Cache / 内存**：
   - 使用得到的物理地址，CPU 向 Cache 系统发起数据访问请求；
   - 若 Cache 命中，则数据直接来自 L1/L2/L3 缓存；
   - 若 Cache 不命中（**Cache miss**），则从主存（DRAM）中加载数据到缓存行，再由 CPU 使用。
5. **完成数据访问**：数据被加载到寄存器或被用于指令执行，整个访问过程完成。

​	这个过程中，**TLB 和 Cache 分别负责加速“地址转换”与“数据访问”**，共同构成现代处理器内存访问延迟优化的核心。

